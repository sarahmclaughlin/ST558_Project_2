<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="st-558-project-2">ST 558 Project 2</h1>
<p>Sarah McLaughlin 6/22/2020</p>
<h1 id="introduction">Introduction</h1>
<p>The data that will be used in this project is from the <em>Online News Popularity Data Set</em> from the <em>UCI Machine Learning Repository</em>. The goal of this project is to create two models (one a linear model, the other an ensemble model) that will be used to predict the number of shares/the probability/if an article has more than 1400 shares. How I picked which variables is detailed below.</p>
<p>The data is from Mashable (<a href="http://www.mashable.com">www.mashable.com</a>) and contains the statistics for articles that were written and published on their website. There are statistics for 39,645 articles.</p>
<p>In this project, I will attempt to create a linear regression model for the data, comparing the Adjusted R Squared values of the models. Due to the very low Adjusted R Squared models, I will instead move to a logistic model. These models produce very small RMSEs.</p>
<p>I will also fit a Random Forest Classification model to the data. I have attempted a few different Random Forest Models but due to computing speed, have only included two models.</p>
<h1 id="data">Data</h1>
<p>Here, I will bring in the data that will be used in this project. With the data, we are trying to predict the number of shares a particular article will receive.</p>
<h2 id="read-in-data">Read in data</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;OnlineNewsPopularity.csv&quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   .default = col_double(),
##   url = col_character()
## )

## See spec(...) for full column specifications.
</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co">#Look at column names  </span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="kw">attributes</span>(data)<span class="op">$</span>names</span></code></pre></div>
<pre><code>##  [1] &quot;url&quot;                          
##  [2] &quot;timedelta&quot;                    
##  [3] &quot;n_tokens_title&quot;               
##  [4] &quot;n_tokens_content&quot;             
##  [5] &quot;n_unique_tokens&quot;              
##  [6] &quot;n_non_stop_words&quot;             
##  [7] &quot;n_non_stop_unique_tokens&quot;     
##  [8] &quot;num_hrefs&quot;                    
##  [9] &quot;num_self_hrefs&quot;               
## [10] &quot;num_imgs&quot;                     
## [11] &quot;num_videos&quot;                   
## [12] &quot;average_token_length&quot;         
## [13] &quot;num_keywords&quot;                 
## [14] &quot;data_channel_is_lifestyle&quot;    
## [15] &quot;data_channel_is_entertainment&quot;
## [16] &quot;data_channel_is_bus&quot;          
## [17] &quot;data_channel_is_socmed&quot;       
## [18] &quot;data_channel_is_tech&quot;         
## [19] &quot;data_channel_is_world&quot;        
## [20] &quot;kw_min_min&quot;                   
## [21] &quot;kw_max_min&quot;                   
## [22] &quot;kw_avg_min&quot;                   
## [23] &quot;kw_min_max&quot;                   
## [24] &quot;kw_max_max&quot;                   
## [25] &quot;kw_avg_max&quot;                   
## [26] &quot;kw_min_avg&quot;                   
## [27] &quot;kw_max_avg&quot;                   
## [28] &quot;kw_avg_avg&quot;                   
## [29] &quot;self_reference_min_shares&quot;    
## [30] &quot;self_reference_max_shares&quot;    
## [31] &quot;self_reference_avg_sharess&quot;   
## [32] &quot;weekday_is_monday&quot;            
## [33] &quot;weekday_is_tuesday&quot;           
## [34] &quot;weekday_is_wednesday&quot;         
## [35] &quot;weekday_is_thursday&quot;          
## [36] &quot;weekday_is_friday&quot;            
## [37] &quot;weekday_is_saturday&quot;          
## [38] &quot;weekday_is_sunday&quot;            
## [39] &quot;is_weekend&quot;                   
## [40] &quot;LDA_00&quot;                       
## [41] &quot;LDA_01&quot;                       
## [42] &quot;LDA_02&quot;                       
## [43] &quot;LDA_03&quot;                       
## [44] &quot;LDA_04&quot;                       
## [45] &quot;global_subjectivity&quot;          
## [46] &quot;global_sentiment_polarity&quot;    
## [47] &quot;global_rate_positive_words&quot;   
## [48] &quot;global_rate_negative_words&quot;   
## [49] &quot;rate_positive_words&quot;          
## [50] &quot;rate_negative_words&quot;          
## [51] &quot;avg_positive_polarity&quot;        
## [52] &quot;min_positive_polarity&quot;        
## [53] &quot;max_positive_polarity&quot;        
## [54] &quot;avg_negative_polarity&quot;        
## [55] &quot;min_negative_polarity&quot;        
## [56] &quot;max_negative_polarity&quot;        
## [57] &quot;title_subjectivity&quot;           
## [58] &quot;title_sentiment_polarity&quot;     
## [59] &quot;abs_title_subjectivity&quot;       
## [60] &quot;abs_title_sentiment_polarity&quot; 
## [61] &quot;shares&quot;
</code></pre>
<h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2>
<p>Here, I will do a basic analysis of my variables to see basic trends, and correlations.</p>
<p><em>Correlation of all Variables</em></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>data &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>url)</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a>correlation &lt;-<span class="st"> </span><span class="kw">cor</span>(data, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<p>Take only those with a correlation to shares of &gt; 0.10.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>shareCor &lt;-<span class="st"> </span>correlation[<span class="dv">60</span>, ] <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.1</span></span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a>corMax &lt;-<span class="st"> </span>correlation[<span class="dv">60</span>, shareCor]</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a>corMax</span></code></pre></div>
<pre><code>##     data_channel_is_socmed                 kw_min_avg 
##                  0.1135715                  0.1032421 
##                 kw_max_avg                 kw_avg_avg 
##                  0.2232914                  0.2556222 
##  self_reference_min_shares  self_reference_max_shares 
##                  0.1815168                  0.1687247 
## self_reference_avg_sharess        weekday_is_saturday 
##                  0.1921745                  0.1088596 
##                 is_weekend        global_subjectivity 
##                  0.1517175                  0.1135482 
##                     shares 
##                  1.0000000
</code></pre>
<p>Based on correlation values, these variables of note that will be used in our analysis and prediction:</p>
<ol>
<li>shares
<ul>
<li>(target variable)</li>
</ul></li>
<li>weekday_is_ variables
<ul>
<li>(weekday published)</li>
</ul></li>
<li>data_channel_is_socmed
<ul>
<li>(social media article)</li>
</ul></li>
<li>kw_max_avg
<ul>
<li>(average keywords for the maximum shares)</li>
</ul></li>
<li>self_reference_minimum_sharess
<ul>
<li>(minimum shares of referenced articles)</li>
</ul></li>
<li>is_weekend
<ul>
<li>(published on a weekend)</li>
</ul></li>
<li>kw_min_avg
<ul>
<li>(average keywords for minimum shares)</li>
</ul></li>
<li>kw_avg_avg
<ul>
<li>(average keywords for average shares)</li>
</ul></li>
<li>self_reference_max_shares
<ul>
<li>(average shares of referenced articles )</li>
</ul></li>
<li>global_subjectivity
<ul>
<li>(text subjectivity)</li>
</ul></li>
</ol>
<h2 id="select-only-needed-variables-from-data-for-specific-day">Select only needed variables from data for specific day</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>day1 &lt;-<span class="kw">paste0</span>(<span class="st">&quot;weekday_is_&quot;</span>, params<span class="op">$</span>day)</span>
<span id="cb8-2"><a href="#cb8-2"></a></span>
<span id="cb8-3"><a href="#cb8-3"></a>day &lt;-<span class="st"> </span><span class="kw">as.name</span>(day1)</span>
<span id="cb8-4"><a href="#cb8-4"></a></span>
<span id="cb8-5"><a href="#cb8-5"></a>data &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">eval</span>(day) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="st">  </span><span class="co">#select only needed variables. is_weekend not included</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="st">  </span><span class="kw">select</span>(shares, data_channel_is_socmed, kw_max_avg, self_reference_avg_sharess, kw_min_avg, </span>
<span id="cb8-9"><a href="#cb8-9"></a>         kw_avg_avg, self_reference_max_shares, global_subjectivity) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="st">  </span><span class="kw">collect</span>()</span></code></pre></div>
<h2 id="create-corrplot-of-all-variables">Create CorrPlot of all variables</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>corr &lt;-<span class="st"> </span><span class="kw">cor</span>(<span class="kw">select</span>(data, <span class="kw">everything</span>()), <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="kw">corrplot</span>(corr, <span class="dt">type =</span> <span class="st">&quot;upper&quot;</span>, <span class="dt">tl.pos =</span> <span class="st">&quot;lt&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="kw">corrplot</span>(corr, <span class="dt">type =</span> <span class="st">&quot;lower&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;number&quot;</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">diag =</span> <span class="ot">FALSE</span>, <span class="dt">tl.pos =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h3 id="analysis">Analysis</h3>
<p>There is a strong correlation between kw_avg_avg and kw_max_avg, as well as self_reference_max_shares and self_reference_avg_shares. I may include these as interactions effects.</p>
<h2 id="make-train-and-test-set">Make Train and Test Set</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># set seed</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="kw">set.seed</span>(<span class="dv">130</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co"># Set indices</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data), <span class="dt">size =</span><span class="kw">nrow</span>(data)<span class="op">*</span><span class="fl">0.7</span>)</span>
<span id="cb10-5"><a href="#cb10-5"></a>test &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data), train)</span>
<span id="cb10-6"><a href="#cb10-6"></a></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co"># Make Train and Test Sets  </span></span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a>dataTrain &lt;-<span class="st"> </span>data[train, ]</span>
<span id="cb10-10"><a href="#cb10-10"></a>dataTest &lt;-<span class="st"> </span>data[test, ]</span></code></pre></div>
<p><strong>Run Quick Summaries on Train Data</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">summary</span>(dataTrain)</span></code></pre></div>
<pre><code>##      shares       data_channel_is_socmed   kw_max_avg    
##  Min.   :    36   Min.   :0.00000        Min.   :  1953  
##  1st Qu.:   900   1st Qu.:0.00000        1st Qu.:  3533  
##  Median :  1300   Median :0.00000        Median :  4290  
##  Mean   :  3298   Mean   :0.05496        Mean   :  5582  
##  3rd Qu.:  2600   3rd Qu.:0.00000        3rd Qu.:  5936  
##  Max.   :843300   Max.   :1.00000        Max.   :135125  
##  self_reference_avg_sharess   kw_min_avg  
##  Min.   :     0             Min.   :  -1  
##  1st Qu.:   954             1st Qu.:   0  
##  Median :  2194             Median :1014  
##  Mean   :  6560             Mean   :1102  
##  3rd Qu.:  5200             3rd Qu.:1996  
##  Max.   :663600             Max.   :3613  
##    kw_avg_avg      self_reference_max_shares
##  Min.   :  424.3   Min.   :     0           
##  1st Qu.: 2364.6   1st Qu.:  1000           
##  Median : 2844.3   Median :  2800           
##  Mean   : 3109.8   Mean   : 10618           
##  3rd Qu.: 3559.6   3rd Qu.:  7900           
##  Max.   :21000.7   Max.   :837700           
##  global_subjectivity
##  Min.   :0.0000     
##  1st Qu.:0.3940     
##  Median :0.4512     
##  Mean   :0.4418     
##  3rd Qu.:0.5066     
##  Max.   :1.0000
</code></pre>
<p>As will be used later, the median number of shares for an article is 1400. From the summaries, you can tell which variables are indicator variables (those with a min of 0 and max of 1; i.e. <code>data_channel_is_socmed</code> and <code>global_subjectivity</code>.) This also shows that the data will need to be standardized when I use the ensemble method.</p>
<p>Overall, the data is quite varied (especially the average variables). You can see that the <code>shares</code> data and <code>self_reference_avg_share</code> data have the same range.</p>
<h2 id="compare-fit-stats-function-to-compare-models">Compare Fit Stats Function to compare models</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>compareFitStats &lt;-<span class="st"> </span><span class="cf">function</span>(fit1, fit2){</span>
<span id="cb13-2"><a href="#cb13-2"></a>  <span class="kw">require</span>(MuMIn)</span>
<span id="cb13-3"><a href="#cb13-3"></a>  fitStats &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fitStat =</span> <span class="kw">c</span>(<span class="st">&quot;Adj R Square&quot;</span>, <span class="st">&quot;AIC&quot;</span>, <span class="st">&quot;AICc&quot;</span>, <span class="st">&quot;BIC&quot;</span>), </span>
<span id="cb13-4"><a href="#cb13-4"></a>              <span class="dt">col1 =</span> <span class="kw">round</span>(<span class="kw">c</span>(<span class="kw">summary</span>(fit1)<span class="op">$</span>adj.r.squared, <span class="kw">AIC</span>(fit1), </span>
<span id="cb13-5"><a href="#cb13-5"></a>                             MuMIn<span class="op">::</span><span class="kw">AICc</span>(fit1), <span class="kw">BIC</span>(fit1)), <span class="dv">3</span>), </span>
<span id="cb13-6"><a href="#cb13-6"></a>              <span class="dt">col2 =</span> <span class="kw">round</span>(<span class="kw">c</span>(<span class="kw">summary</span>(fit2)<span class="op">$</span>adj.r.squared, <span class="kw">AIC</span>(fit2), </span>
<span id="cb13-7"><a href="#cb13-7"></a>                             MuMIn<span class="op">::</span><span class="kw">AICc</span>(fit2), <span class="kw">BIC</span>(fit2)), <span class="dv">3</span>))</span>
<span id="cb13-8"><a href="#cb13-8"></a>  </span>
<span id="cb13-9"><a href="#cb13-9"></a>  <span class="co">#put names on returned df  </span></span>
<span id="cb13-10"><a href="#cb13-10"></a>  calls &lt;-<span class="st"> </span><span class="kw">as.list</span>(<span class="kw">match.call</span>())</span>
<span id="cb13-11"><a href="#cb13-11"></a>  calls[[<span class="dv">1</span>]] &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb13-12"><a href="#cb13-12"></a>  <span class="kw">names</span>(fitStats[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>])&lt;-<span class="st"> </span><span class="kw">unlist</span>(calls)</span>
<span id="cb13-13"><a href="#cb13-13"></a>  fitStats</span>
<span id="cb13-14"><a href="#cb13-14"></a>}</span></code></pre></div>
<h1 id="linear-regression-model">Linear Regression Model</h1>
<p>I will begin by running a regression model with all of the variables.</p>
<p><strong>allVarFit</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>allVarFit &lt;-<span class="st"> </span><span class="kw">lm</span>(shares <span class="op">~</span>., <span class="dt">data =</span> dataTrain)</span>
<span id="cb14-2"><a href="#cb14-2"></a></span>
<span id="cb14-3"><a href="#cb14-3"></a>allVarFit</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = shares ~ ., data = dataTrain)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -2.613e+03                  -2.347e+02  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -2.354e-01                   3.167e-02  
##                 kw_min_avg                  kw_avg_avg  
##                 -2.926e-01                   1.859e+00  
##  self_reference_max_shares         global_subjectivity  
##                 -8.601e-03                   3.765e+03
</code></pre>
<p>Then, I will create another linear model with the interaction effects to see if it makes a difference.</p>
<p><strong>intLM</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>intLM &lt;-<span class="st"> </span><span class="kw">lm</span>(shares <span class="op">~</span><span class="st"> </span>data_channel_is_socmed <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span>kw_min_avg <span class="op">+</span></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb16-5"><a href="#cb16-5"></a><span class="st">                  </span>self_reference_max_shares <span class="op">+</span></span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="st">                  </span>global_subjectivity <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-7"><a href="#cb16-7"></a><span class="st">                  </span>kw_avg_avg<span class="op">:</span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-8"><a href="#cb16-8"></a><span class="st">                  </span>self_reference_max_shares<span class="op">:</span>self_reference_avg_sharess, </span>
<span id="cb16-9"><a href="#cb16-9"></a>                <span class="dt">data =</span> dataTrain</span>
<span id="cb16-10"><a href="#cb16-10"></a>)</span>
<span id="cb16-11"><a href="#cb16-11"></a></span>
<span id="cb16-12"><a href="#cb16-12"></a>intLM</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = shares ~ data_channel_is_socmed + kw_max_avg + kw_min_avg + 
##     self_reference_avg_sharess + kw_avg_avg + self_reference_max_shares + 
##     global_subjectivity + kw_avg_avg:kw_max_avg + self_reference_max_shares:self_reference_avg_sharess, 
##     data = dataTrain)
## 
## Coefficients:
##                                          (Intercept)  
##                                           -2.299e+03  
##                               data_channel_is_socmed  
##                                           -4.040e+02  
##                                           kw_max_avg  
##                                           -1.831e-01  
##                                           kw_min_avg  
##                                           -2.508e-01  
##                           self_reference_avg_sharess  
##                                            9.598e-02  
##                                           kw_avg_avg  
##                                            1.654e+00  
##                            self_reference_max_shares  
##                                            3.990e-04  
##                                  global_subjectivity  
##                                            2.989e+03  
##                                kw_max_avg:kw_avg_avg  
##                                           -1.952e-06  
## self_reference_avg_sharess:self_reference_max_shares  
##                                           -1.430e-07
</code></pre>
<h2 id="comparison-of-two-models">Comparison of Two Models</h2>
<p>I will compare the two models using the compareFitStats function.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">compareFitStats</span>(allVarFit, intLM)</span></code></pre></div>
<pre><code>##        fitStat       col1       col2
## 1 Adj R Square      0.011      0.014
## 2          AIC 114183.587 114168.606
## 3         AICc 114183.622 114168.657
## 4          BIC 114242.602 114240.735
</code></pre>
<h3 id="analysis-1">Analysis</h3>
<p>Neither model fits the data well. I am going to try a logistic regression model instead.</p>
<h1 id="logistic-model">Logistic Model</h1>
<p>First, I need to create a logical variable to reference whether the number of shares is less than 1400 or greater than 1400. I am still going to use the same variables as those in my linear regression attempt.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a>data1 &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">logShares =</span> <span class="kw">ifelse</span>(shares <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="dv">1</span>, <span class="dv">0</span>)) </span>
<span id="cb20-2"><a href="#cb20-2"></a>data1 &lt;-<span class="st"> </span>data1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(logShares, <span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>shares)</span>
<span id="cb20-3"><a href="#cb20-3"></a></span>
<span id="cb20-4"><a href="#cb20-4"></a><span class="co">#Create New Test and Train Set with logShares Variable. Set seed gives same train and test set. </span></span>
<span id="cb20-5"><a href="#cb20-5"></a></span>
<span id="cb20-6"><a href="#cb20-6"></a><span class="co"># set seed</span></span>
<span id="cb20-7"><a href="#cb20-7"></a><span class="kw">set.seed</span>(<span class="dv">130</span>)</span>
<span id="cb20-8"><a href="#cb20-8"></a><span class="co"># Set indices</span></span>
<span id="cb20-9"><a href="#cb20-9"></a>train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data1), <span class="dt">size =</span><span class="kw">nrow</span>(data1)<span class="op">*</span><span class="fl">0.7</span>)</span>
<span id="cb20-10"><a href="#cb20-10"></a>test &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data1), train)</span>
<span id="cb20-11"><a href="#cb20-11"></a></span>
<span id="cb20-12"><a href="#cb20-12"></a><span class="co"># Make Train and Test Sets  </span></span>
<span id="cb20-13"><a href="#cb20-13"></a></span>
<span id="cb20-14"><a href="#cb20-14"></a>data1Train &lt;-<span class="st"> </span>data1[train, ]</span>
<span id="cb20-15"><a href="#cb20-15"></a>data1Test &lt;-<span class="st"> </span>data1[test, ]</span>
<span id="cb20-16"><a href="#cb20-16"></a></span>
<span id="cb20-17"><a href="#cb20-17"></a>data1</span></code></pre></div>
<pre><code>## # A tibble: 7,435 x 8
##    logShares data_channel_is~ kw_max_avg self_reference_~
##        &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;
##  1         0                0      1953.             527 
##  2         0                0      2082.               0 
##  3         0                0      1953.            2989 
##  4         1                0      2340.               0 
##  5         1                0      1953.            2692.
##  6         1                1      2322.            6600 
##  7         0                0      2340.            3151.
##  8         0                0      4151                0 
##  9         1                0      5429.            1100 
## 10         0                0      8567.            2500 
## # ... with 7,425 more rows, and 4 more variables:
## #   kw_min_avg &lt;dbl&gt;, kw_avg_avg &lt;dbl&gt;,
## #   self_reference_max_shares &lt;dbl&gt;,
## #   global_subjectivity &lt;dbl&gt;
</code></pre>
<p>Here, I will fit a logistic regression model using the <code>glm()</code> function with the <code>&quot;binomial&quot;</code> family. I will look at how the removal of certain variables changes the AIC value for each model.</p>
<p><strong>GLM ALL Model</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a>glmALL &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span>., <span class="dt">data =</span> data1Train, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb22-2"><a href="#cb22-2"></a></span>
<span id="cb22-3"><a href="#cb22-3"></a>glmALL</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ ., family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -1.657e+00                   1.004e+00  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -6.629e-05                   3.691e-06  
##                 kw_min_avg                  kw_avg_avg  
##                 -1.106e-04                   5.298e-04  
##  self_reference_max_shares         global_subjectivity  
##                  6.184e-07                   9.071e-01  
## 
## Degrees of Freedom: 5203 Total (i.e. Null);  5196 Residual
## Null Deviance:       7214 
## Residual Deviance: 6943  AIC: 6959
</code></pre>
<p>I will remove <code>kw_avg_min</code> variable just to be able to compare fits of the two logistic models.</p>
<p><strong>GLM All but One Model</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a>glmAllButOne &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span>data_channel_is_socmed <span class="op">+</span><span class="st"> </span></span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb24-3"><a href="#cb24-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb24-4"><a href="#cb24-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb24-5"><a href="#cb24-5"></a><span class="st">                  </span>self_reference_max_shares <span class="op">+</span></span>
<span id="cb24-6"><a href="#cb24-6"></a><span class="st">                  </span>global_subjectivity, </span>
<span id="cb24-7"><a href="#cb24-7"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb24-8"><a href="#cb24-8"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb24-9"><a href="#cb24-9"></a>)</span>
<span id="cb24-10"><a href="#cb24-10"></a></span>
<span id="cb24-11"><a href="#cb24-11"></a>glmAllButOne</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ data_channel_is_socmed + kw_max_avg + 
##     self_reference_avg_sharess + kw_avg_avg + self_reference_max_shares + 
##     global_subjectivity, family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -1.547e+00                   9.947e-01  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -4.877e-05                   3.894e-06  
##                 kw_avg_avg   self_reference_max_shares  
##                  4.191e-04                   5.290e-07  
##        global_subjectivity  
##                  9.395e-01  
## 
## Degrees of Freedom: 5203 Total (i.e. Null);  5197 Residual
## Null Deviance:       7214 
## Residual Deviance: 6954  AIC: 6968
</code></pre>
<h3 id="analysis-2">Analysis</h3>
<p>The AIC for the glmAllButOne model is much higher than the all variable model. I will remove another variable, <code>global_subjectivity</code> (next smallest correlation) and see if that helps.</p>
<p><strong>glm All But Two Model</strong></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a>glmAllButTwo &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span>data_channel_is_socmed <span class="op">+</span><span class="st"> </span></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb26-5"><a href="#cb26-5"></a><span class="st">                  </span>self_reference_max_shares, </span>
<span id="cb26-6"><a href="#cb26-6"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb26-7"><a href="#cb26-7"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb26-8"><a href="#cb26-8"></a>)</span>
<span id="cb26-9"><a href="#cb26-9"></a></span>
<span id="cb26-10"><a href="#cb26-10"></a>glmAllButTwo</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ data_channel_is_socmed + kw_max_avg + 
##     self_reference_avg_sharess + kw_avg_avg + self_reference_max_shares, 
##     family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -1.149e+00                   1.002e+00  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -4.909e-05                   4.625e-06  
##                 kw_avg_avg   self_reference_max_shares  
##                  4.239e-04                   4.741e-07  
## 
## Degrees of Freedom: 5203 Total (i.e. Null);  5198 Residual
## Null Deviance:       7214 
## Residual Deviance: 6969  AIC: 6981
</code></pre>
<p>##Analysis<br />
Remove <code>data_channel_is_socmed</code>.</p>
<p><strong>glm All But Three Model</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a>glmAllButThree &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span></span>
<span id="cb28-2"><a href="#cb28-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb28-4"><a href="#cb28-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="st">                  </span>self_reference_max_shares,</span>
<span id="cb28-6"><a href="#cb28-6"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb28-7"><a href="#cb28-7"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb28-8"><a href="#cb28-8"></a>)</span>
<span id="cb28-9"><a href="#cb28-9"></a></span>
<span id="cb28-10"><a href="#cb28-10"></a>glmAllButThree</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ kw_max_avg + self_reference_avg_sharess + 
##     kw_avg_avg + self_reference_max_shares, family = &quot;binomial&quot;, 
##     data = data1Train)
## 
## Coefficients:
##                (Intercept)                  kw_max_avg  
##                 -1.115e+00                  -5.255e-05  
## self_reference_avg_sharess                  kw_avg_avg  
##                  5.228e-06                   4.353e-04  
##  self_reference_max_shares  
##                  3.429e-07  
## 
## Degrees of Freedom: 5203 Total (i.e. Null);  5199 Residual
## Null Deviance:       7214 
## Residual Deviance: 7028  AIC: 7038
</code></pre>
<p>##Analysis<br />
Remove <code>self_reference_max_shares</code>.</p>
<p><strong>glm All But Four Model</strong></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a>glmAllButFour &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span></span>
<span id="cb30-2"><a href="#cb30-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb30-4"><a href="#cb30-4"></a><span class="st">                  </span>kw_avg_avg, </span>
<span id="cb30-5"><a href="#cb30-5"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb30-6"><a href="#cb30-6"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb30-7"><a href="#cb30-7"></a>)</span>
<span id="cb30-8"><a href="#cb30-8"></a>glmAllButFour</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ kw_max_avg + self_reference_avg_sharess + 
##     kw_avg_avg, family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)                  kw_max_avg  
##                 -1.115e+00                  -5.253e-05  
## self_reference_avg_sharess                  kw_avg_avg  
##                  5.839e-06                   4.350e-04  
## 
## Degrees of Freedom: 5203 Total (i.e. Null);  5200 Residual
## Null Deviance:       7214 
## Residual Deviance: 7028  AIC: 7036
</code></pre>
<h2 id="analysis-3">Analysis</h2>
<p>Did not help. Will keep <code>self_reference_max_shares</code>.</p>
<h2 id="comparison-of-all-four-logistic-models">Comparison of all Four Logistic Models</h2>
<p>I will predict the test data and compare the RMSEs of those.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a><span class="co">#Make predictions  </span></span>
<span id="cb32-2"><a href="#cb32-2"></a>predALL &lt;-<span class="st"> </span><span class="kw">predict</span>(glmALL, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-3"><a href="#cb32-3"></a>predALLbutOne &lt;-<span class="st"> </span><span class="kw">predict</span>(glmAllButOne, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-4"><a href="#cb32-4"></a>predALLbutTwo &lt;-<span class="st"> </span><span class="kw">predict</span>(glmAllButTwo, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-5"><a href="#cb32-5"></a>predALLbutThree &lt;-<span class="st"> </span><span class="kw">predict</span>(glmAllButThree, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-6"><a href="#cb32-6"></a></span>
<span id="cb32-7"><a href="#cb32-7"></a><span class="co">#Calculate RMSE  </span></span>
<span id="cb32-8"><a href="#cb32-8"></a>AllMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALL)</span>
<span id="cb32-9"><a href="#cb32-9"></a>OneMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALLbutOne)</span>
<span id="cb32-10"><a href="#cb32-10"></a>TwoMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALLbutTwo)</span>
<span id="cb32-11"><a href="#cb32-11"></a>ThreeMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALLbutThree)</span>
<span id="cb32-12"><a href="#cb32-12"></a></span>
<span id="cb32-13"><a href="#cb32-13"></a>matMSE &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(AllMSE, OneMSE, TwoMSE, ThreeMSE), <span class="dt">nrow =</span> <span class="dv">1</span>, <span class="dt">ncol =</span> <span class="dv">4</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</span>
<span id="cb32-14"><a href="#cb32-14"></a></span>
<span id="cb32-15"><a href="#cb32-15"></a>matMSE</span></code></pre></div>
<pre><code>##           [,1]      [,2]      [,3]      [,4]
## [1,] 0.7825694 0.7795626 0.7759651 0.7639805
</code></pre>
<h3 id="analysis-4">Analysis</h3>
<p>The glmAllButThree produces the smallest MSE. I will use this as my model for the data. The glmAllButThree also produces the highest AIC value.</p>
<h1 id="ensemble-model">Ensemble Model</h1>
<p>From the past homework assigment, it seems that each of the ensemble methods that we covered are equally efficient. I am going to use the Random Forest model to fit my data. Overall, Random Forest is better than bagging and boosting trees take longer to do. I will add a class variable (less than 1400, more than 1400) that I will predict on the test data.</p>
<h2 id="fix-train-and-test-data">Fix Train and Test Data</h2>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a>dataTrain &lt;-<span class="st"> </span>dataTrain <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">group =</span> <span class="kw">ifelse</span>(shares <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="st">&quot;less than 1400&quot;</span>, <span class="st">&quot;more than 1400&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb34-2"><a href="#cb34-2"></a><span class="st">  </span><span class="kw">select</span>(group, kw_max_avg, self_reference_avg_sharess, </span>
<span id="cb34-3"><a href="#cb34-3"></a>         kw_min_avg, kw_avg_avg, self_reference_max_shares, </span>
<span id="cb34-4"><a href="#cb34-4"></a>         global_subjectivity) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">collect</span>()</span>
<span id="cb34-5"><a href="#cb34-5"></a></span>
<span id="cb34-6"><a href="#cb34-6"></a>dataTrain<span class="op">$</span>group &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dataTrain<span class="op">$</span>group)</span>
<span id="cb34-7"><a href="#cb34-7"></a></span>
<span id="cb34-8"><a href="#cb34-8"></a>dataTrain</span></code></pre></div>
<pre><code>## # A tibble: 5,204 x 7
##    group kw_max_avg self_reference_~ kw_min_avg kw_avg_avg
##    &lt;fct&gt;      &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1 less~      3798.            1657.      1545.      2501.
##  2 less~      3398.            5200       1912.      2569.
##  3 less~      3867.            1200       2541.      3133.
##  4 more~      8918.           12200       2917.      5302.
##  5 more~      8042            42500       3310.      4745.
##  6 less~      2963.            2698.      1759       2429.
##  7 more~      7704.           16800          0       3769.
##  8 more~      3253.            5894.      1626.      2564.
##  9 more~      7713.            6250       3580.      5303.
## 10 more~      7680.           37600          0       4319.
## # ... with 5,194 more rows, and 2 more variables:
## #   self_reference_max_shares &lt;dbl&gt;,
## #   global_subjectivity &lt;dbl&gt;
</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a>dataTest &lt;-<span class="st"> </span>dataTest <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">group =</span><span class="kw">ifelse</span>(shares <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="st">&quot;less than 1400&quot;</span>, <span class="st">&quot;more than 1400&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="st">  </span><span class="kw">select</span>(group, kw_max_avg, self_reference_avg_sharess, </span>
<span id="cb36-3"><a href="#cb36-3"></a>         kw_min_avg, kw_avg_avg, self_reference_max_shares, </span>
<span id="cb36-4"><a href="#cb36-4"></a>         global_subjectivity) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">collect</span>()</span>
<span id="cb36-5"><a href="#cb36-5"></a></span>
<span id="cb36-6"><a href="#cb36-6"></a>dataTest<span class="op">$</span>group &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dataTest<span class="op">$</span>group)</span></code></pre></div>
<p><strong>Random Forest Model</strong></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># train control parameters  </span></span>
<span id="cb37-2"><a href="#cb37-2"></a>trctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb37-3"><a href="#cb37-3"></a></span>
<span id="cb37-4"><a href="#cb37-4"></a>rfFit&lt;-<span class="st"> </span><span class="kw">train</span>(group<span class="op">~</span>., <span class="dt">data =</span> dataTrain, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> trctrl, <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span></code></pre></div>
<p><strong>Predict Data with rfFit</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a>rfPred &lt;-<span class="st"> </span><span class="kw">predict</span>(rfFit, <span class="kw">select</span>(dataTest, <span class="op">-</span><span class="st">&quot;group&quot;</span>))</span></code></pre></div>
<p><strong>Compare Predictions to Actual</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>fullTbl &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">data.frame</span>(rfPred, dataTest<span class="op">$</span>group))</span>
<span id="cb39-2"><a href="#cb39-2"></a></span>
<span id="cb39-3"><a href="#cb39-3"></a>fullTbl</span></code></pre></div>
<pre><code>##                 dataTest.group
## rfPred           less than 1400 more than 1400
##   less than 1400            853            482
##   more than 1400            406            490
</code></pre>
<p><strong>Find MisClassification Rate</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a>rfMis &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(fullTbl)<span class="op">/</span><span class="kw">sum</span>(fullTbl))</span>
<span id="cb41-2"><a href="#cb41-2"></a></span>
<span id="cb41-3"><a href="#cb41-3"></a>rfMis</span></code></pre></div>
<pre><code>## [1] 0.3980278
</code></pre>
<h3 id="analysis-5">Analysis</h3>
<p>This a pretty large misclassification rate. I will choose less variables to see if it helps.</p>
<p><strong>One Variable Random Forest</strong></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="co"># no kw_min_avg, has lowest correlation </span></span>
<span id="cb43-2"><a href="#cb43-2"></a>rf1 &lt;-<span class="st"> </span><span class="kw">train</span>(group <span class="op">~</span><span class="st"> </span>kw_max_avg <span class="op">+</span><span class="st"> </span>self_reference_avg_sharess <span class="op">+</span><span class="st">  </span></span>
<span id="cb43-3"><a href="#cb43-3"></a><span class="st">         </span><span class="op">+</span><span class="st"> </span>kw_avg_avg <span class="op">+</span><span class="st"> </span>self_reference_max_shares <span class="op">+</span><span class="st">  </span></span>
<span id="cb43-4"><a href="#cb43-4"></a><span class="st">         </span>global_subjectivity, <span class="dt">data =</span> dataTrain, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> trctrl, <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))  </span></code></pre></div>
<p><strong>Predict Data with rf1</strong></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1"></a>rf1Pred &lt;-<span class="st"> </span><span class="kw">predict</span>(rf1, <span class="kw">select</span>(dataTest, <span class="op">-</span><span class="st">&quot;group&quot;</span>))  </span></code></pre></div>
<p><strong>Compare Predictions to Actual</strong></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a>fullTbl &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">data.frame</span>(rf1Pred, dataTest<span class="op">$</span>group))  </span>
<span id="cb45-2"><a href="#cb45-2"></a></span>
<span id="cb45-3"><a href="#cb45-3"></a>fullTbl</span></code></pre></div>
<pre><code>##                 dataTest.group
## rf1Pred          less than 1400 more than 1400
##   less than 1400            834            495
##   more than 1400            425            477
</code></pre>
<p><strong>Find MisClassification Rate</strong></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>rfMis &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(fullTbl)<span class="op">/</span><span class="kw">sum</span>(fullTbl))</span>
<span id="cb47-2"><a href="#cb47-2"></a></span>
<span id="cb47-3"><a href="#cb47-3"></a>rfMis</span></code></pre></div>
<pre><code>## [1] 0.4123711
</code></pre>
<h3 id="analysis-6">Analysis</h3>
<p>This does not help. I will keep my first Random Forest Model for prediction.</p>
<h1 id="models-used">Models Used</h1>
<p>Overall, I have chosen the following models for my data.</p>
<ol>
<li>glmAllbutThree: Logistic Regression Model</li>
<li>rfFit : Random Forest Model</li>
</ol>

</body>
</html>
