<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,d09GRgABAAAAAAZwABAAAAAACFQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABEU0lHAAAGaAAAAAgAAAAIAAAAAUdTVUIAAAZcAAAACgAAAAoAAQAAT1MvMgAAAyQAAABJAAAAYFYEU3RjbWFwAAADcAAAAEUAAACAAJThvmN2dCAAAATkAAAABAAAAAQAAAAAZnBnbQAAA7gAAACyAAABCUM+8IhnYXNwAAAGTAAAABAAAAAQABoAI2dseWYAAAFsAAABPAAAAZwcEq9taGVhZAAAAsgAAAA0AAAANgh4a91oaGVhAAADCAAAABoAAAAkCA8DRGhtdHgAAAL8AAAADAAAAAwGAACfbG9jYQAAAsAAAAAIAAAACABiATBtYXhwAAACqAAAABgAAAAgAA8ASm5hbWUAAAToAAABQgAAAlXu73sOcG9zdAAABiwAAAAeAAAAME3QpOBwcmVwAAAEbAAAAHYAAAB/aFGpk3jaTY6xa8JAGMW/O62BDi0tJLYQincXEypYIiGJjSgHniQ6umTsUEyLm5BV6NDBP8Tpts6F0v+k/0an2i+itHDw3v2+9+DBKTzsJNnWJNTgHEy4BgG3EMI9DCEDOGEXzDADU5hBKMIgNPZqoD3SilVaXZCER3/I7AtxEJLtzzuZfI+VVkprxTlXShWKb3TBecG11rwoNlmmn1P2WYcJczl32etSpKnziC7lQyWe1smVPy/Lt7Kc+0vWY/gAgIIEqAN9we0pwKXreiMasxvabDQMM4riO+qxM2ogwDGOZTXxwxDiycQIcoYFBLj5K3EIaSctAq2kTYiw+ymhce7vwM9jSqO8JyVd5RH9gyTt2+J/yUmYlIR0s04n6+7Vm1ozezUeLEaUjhaDSuXHwVRgvLJn1tQ7xiuVv/ocTRF42mNgZGBgYGbwZOBiAAFGJBIMAAizAFoAAABiAGIAznjaY2BkYGAA4in8zwXi+W2+MjCzMIDApSwvXzC97Z4Ig8N/BxYGZgcgl52BCSQKAA3jCV8CAABfAAAAAAQAAEB42mNgZGBg4f3vACQZQABIMjKgAmYAKEgBXgAAeNpjYGY6wTiBgZWBg2kmUxoDA4MPhGZMYzBi1AHygVLYQUCaawqDA4PChxhmh/8ODDEsvAwHgMKMIDnGL0x7gJQCAwMAJd4MFwAAAHjaY2BgYGaA4DAGRgYQkAHyGMF8NgYrIM3JIAGVYYDT+AEjAwuDFpBmA9KMDEwMCh9i/v8H8sH0/4dQc1iAmAkALaUKLgAAAHjaTY9LDsIgEIbtgqHUPpDi3gPoBVyRTmTddOmqTXThEXqrob2gQ1FjwpDvfwCBdmdXC5AVKFu3e5MfNFJ29KTQT48Ob9/lqYwOGZxeUelN2U2R6+cArgtCJpauW7UQBqnFkUsjAY/kOU1cP+DAgvxwn1chZDwUbd6CFimGXwzwF6tPbFIcjEl+vvmM/byA48e6tWrKArm4ZJlCbdsrxksL1AwWn/yBSJKpYbq8AXaaTb8AAHja28jAwOC00ZrBeQNDQOWO//sdBBgYGRiYWYAEELEwMTE4uzo5Zzo5b2BxdnFOcALxNjA6b2ByTswC8jYwg0VlNuoCTWAMqNzMzsoK1rEhNqByEyerg5PMJlYuVueETKcd/89uBpnpvIEVomeHLoMsAAe1Id4AAAAAAAB42oWQT07CQBTGv0JBhagk7HQzKxca2sJCE1hDt4QF+9JOS0nbaaYDCQfwCJ7Au3AHj+LO13FMmm6cl7785vven0kBjHCBhfpYuNa5Ph1c0e2Xu3jEvWG7UdPDLZ4N92nOm+EBXuAbHmIMSRMs+4aUEd4Nd3CHD8NdvOLTsA2GL8M9PODbcL+hD7C1xoaHeLJSEao0FEW14ckxC+TU8TxvsY6X0eLPmRhry2WVioLpkrbp84LLQPGI7c6sOiUzpWIWS5GzlSgUzzLBSikOPFTOXqly7rqx0Z1Q5BAIoZBSFihQYQOOBEdkCOgXTOHA07HAGjGWiIjaPZNW13/+lm6S9FT7rLHFJ6fQbkATOG1j2OFMucKJJsxIVfQORl+9Jyda6Sl1dUYhSCm1dyClfoeDve4qMYdLEbfqHf3O/AdDumsjAAB42mNgYoAAZQYjBmyAGYQZmdhL8zLdDEydARfoAqIAAAABAAMABwAKABMAB///AA8AAQAAAAAAAAAAAAAAAAABAAAAAA==) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="st-558-project-2">ST 558 Project 2</h1>
<p>Sarah McLaughlin 6/22/2020</p>
<h1 id="introduction">Introduction</h1>
<p>The data that will be used in this project is from the <em>Online News Popularity Data Set</em> from the <em>UCI Machine Learning Repository</em>. The goal of this project is to create two models (one a linear model, the other an ensemble model) that will be used to predict the number of shares/the probability/if an article has more than 1400 shares. How I picked which variables is detailed below.</p>
<p>The data is from Mashable (<a href="http://www.mashable.com">www.mashable.com</a>) and contains the statistics for articles that were written and published on their website. There are statistics for 39,645 articles.</p>
<p>In this project, I will attempt to create a linear regression model for the data, comparing the Adjusted R Squared values of the models. Due to the very low Adjusted R Squared models, I will instead move to a logistic model. These models produce very small RMSEs.</p>
<p>I will also fit a Random Forest Classification model to the data. I have attempted a few different Random Forest Models but due to computing speed, have only included two models.</p>
<h1 id="data">Data</h1>
<p>Here, I will bring in the data that will be used in this project. With the data, we are trying to predict the number of shares a particular article will receive.</p>
<h2 id="read-in-data">Read in data</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;OnlineNewsPopularity.csv&quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   .default = col_double(),
##   url = col_character()
## )

## See spec(...) for full column specifications.
</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co">#Look at column names  </span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="kw">attributes</span>(data)<span class="op">$</span>names</span></code></pre></div>
<pre><code>##  [1] &quot;url&quot;                          
##  [2] &quot;timedelta&quot;                    
##  [3] &quot;n_tokens_title&quot;               
##  [4] &quot;n_tokens_content&quot;             
##  [5] &quot;n_unique_tokens&quot;              
##  [6] &quot;n_non_stop_words&quot;             
##  [7] &quot;n_non_stop_unique_tokens&quot;     
##  [8] &quot;num_hrefs&quot;                    
##  [9] &quot;num_self_hrefs&quot;               
## [10] &quot;num_imgs&quot;                     
## [11] &quot;num_videos&quot;                   
## [12] &quot;average_token_length&quot;         
## [13] &quot;num_keywords&quot;                 
## [14] &quot;data_channel_is_lifestyle&quot;    
## [15] &quot;data_channel_is_entertainment&quot;
## [16] &quot;data_channel_is_bus&quot;          
## [17] &quot;data_channel_is_socmed&quot;       
## [18] &quot;data_channel_is_tech&quot;         
## [19] &quot;data_channel_is_world&quot;        
## [20] &quot;kw_min_min&quot;                   
## [21] &quot;kw_max_min&quot;                   
## [22] &quot;kw_avg_min&quot;                   
## [23] &quot;kw_min_max&quot;                   
## [24] &quot;kw_max_max&quot;                   
## [25] &quot;kw_avg_max&quot;                   
## [26] &quot;kw_min_avg&quot;                   
## [27] &quot;kw_max_avg&quot;                   
## [28] &quot;kw_avg_avg&quot;                   
## [29] &quot;self_reference_min_shares&quot;    
## [30] &quot;self_reference_max_shares&quot;    
## [31] &quot;self_reference_avg_sharess&quot;   
## [32] &quot;weekday_is_monday&quot;            
## [33] &quot;weekday_is_tuesday&quot;           
## [34] &quot;weekday_is_wednesday&quot;         
## [35] &quot;weekday_is_thursday&quot;          
## [36] &quot;weekday_is_friday&quot;            
## [37] &quot;weekday_is_saturday&quot;          
## [38] &quot;weekday_is_sunday&quot;            
## [39] &quot;is_weekend&quot;                   
## [40] &quot;LDA_00&quot;                       
## [41] &quot;LDA_01&quot;                       
## [42] &quot;LDA_02&quot;                       
## [43] &quot;LDA_03&quot;                       
## [44] &quot;LDA_04&quot;                       
## [45] &quot;global_subjectivity&quot;          
## [46] &quot;global_sentiment_polarity&quot;    
## [47] &quot;global_rate_positive_words&quot;   
## [48] &quot;global_rate_negative_words&quot;   
## [49] &quot;rate_positive_words&quot;          
## [50] &quot;rate_negative_words&quot;          
## [51] &quot;avg_positive_polarity&quot;        
## [52] &quot;min_positive_polarity&quot;        
## [53] &quot;max_positive_polarity&quot;        
## [54] &quot;avg_negative_polarity&quot;        
## [55] &quot;min_negative_polarity&quot;        
## [56] &quot;max_negative_polarity&quot;        
## [57] &quot;title_subjectivity&quot;           
## [58] &quot;title_sentiment_polarity&quot;     
## [59] &quot;abs_title_subjectivity&quot;       
## [60] &quot;abs_title_sentiment_polarity&quot; 
## [61] &quot;shares&quot;
</code></pre>
<h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2>
<p>Here, I will do a basic analysis of my variables to see basic trends, and correlations.</p>
<p><em>Correlation of all Variables</em></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>data &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>url)</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a>correlation &lt;-<span class="st"> </span><span class="kw">cor</span>(data, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<p>Take only those with a correlation to shares of &gt; 0.10.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>shareCor &lt;-<span class="st"> </span>correlation[<span class="dv">60</span>, ] <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.1</span></span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a>corMax &lt;-<span class="st"> </span>correlation[<span class="dv">60</span>, shareCor]</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a>corMax</span></code></pre></div>
<pre><code>##     data_channel_is_socmed                 kw_min_avg 
##                  0.1135715                  0.1032421 
##                 kw_max_avg                 kw_avg_avg 
##                  0.2232914                  0.2556222 
##  self_reference_min_shares  self_reference_max_shares 
##                  0.1815168                  0.1687247 
## self_reference_avg_sharess        weekday_is_saturday 
##                  0.1921745                  0.1088596 
##                 is_weekend        global_subjectivity 
##                  0.1517175                  0.1135482 
##                     shares 
##                  1.0000000
</code></pre>
<p>Based on correlation values, these variables of note that will be used in our analysis and prediction:</p>
<ol>
<li>shares
<ul>
<li>(target variable)</li>
</ul></li>
<li>weekday_is_ variables
<ul>
<li>(weekday published)</li>
</ul></li>
<li>data_channel_is_socmed
<ul>
<li>(social media article)</li>
</ul></li>
<li>kw_max_avg
<ul>
<li>(average keywords for the maximum shares)</li>
</ul></li>
<li>self_reference_minimum_sharess
<ul>
<li>(minimum shares of referenced articles)</li>
</ul></li>
<li>is_weekend
<ul>
<li>(published on a weekend)</li>
</ul></li>
<li>kw_min_avg
<ul>
<li>(average keywords for minimum shares)</li>
</ul></li>
<li>kw_avg_avg
<ul>
<li>(average keywords for average shares)</li>
</ul></li>
<li>self_reference_max_shares
<ul>
<li>(average shares of referenced articles )</li>
</ul></li>
<li>global_subjectivity
<ul>
<li>(text subjectivity)</li>
</ul></li>
</ol>
<h2 id="select-only-needed-variables-from-data-for-specific-day">Select only needed variables from data for specific day</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>day1 &lt;-<span class="kw">paste0</span>(<span class="st">&quot;weekday_is_&quot;</span>, params<span class="op">$</span>day)</span>
<span id="cb8-2"><a href="#cb8-2"></a></span>
<span id="cb8-3"><a href="#cb8-3"></a>day &lt;-<span class="st"> </span><span class="kw">as.name</span>(day1)</span>
<span id="cb8-4"><a href="#cb8-4"></a></span>
<span id="cb8-5"><a href="#cb8-5"></a>data &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">eval</span>(day) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="st">  </span><span class="co">#select only needed variables. is_weekend not included</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="st">  </span><span class="kw">select</span>(shares, data_channel_is_socmed, kw_max_avg, self_reference_avg_sharess, kw_min_avg, </span>
<span id="cb8-9"><a href="#cb8-9"></a>         kw_avg_avg, self_reference_max_shares, global_subjectivity) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="st">  </span><span class="kw">collect</span>()</span></code></pre></div>
<h2 id="create-corrplot-of-all-variables">Create CorrPlot of all variables</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>corr &lt;-<span class="st"> </span><span class="kw">cor</span>(<span class="kw">select</span>(data, <span class="kw">everything</span>()), <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="kw">corrplot</span>(corr, <span class="dt">type =</span> <span class="st">&quot;upper&quot;</span>, <span class="dt">tl.pos =</span> <span class="st">&quot;lt&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="kw">corrplot</span>(corr, <span class="dt">type =</span> <span class="st">&quot;lower&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;number&quot;</span>, <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">diag =</span> <span class="ot">FALSE</span>, <span class="dt">tl.pos =</span> <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<h3 id="analysis">Analysis</h3>
<p>There is a strong correlation between kw_avg_avg and kw_max_avg, as well as self_reference_max_shares and self_reference_avg_shares. I may include these as interactions effects.</p>
<h2 id="make-train-and-test-set">Make Train and Test Set</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># set seed</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="kw">set.seed</span>(<span class="dv">130</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co"># Set indices</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data), <span class="dt">size =</span><span class="kw">nrow</span>(data)<span class="op">*</span><span class="fl">0.7</span>)</span>
<span id="cb10-5"><a href="#cb10-5"></a>test &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data), train)</span>
<span id="cb10-6"><a href="#cb10-6"></a></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co"># Make Train and Test Sets  </span></span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a>dataTrain &lt;-<span class="st"> </span>data[train, ]</span>
<span id="cb10-10"><a href="#cb10-10"></a>dataTest &lt;-<span class="st"> </span>data[test, ]</span></code></pre></div>
<p><strong>Run Quick Summaries on Train Data</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">summary</span>(dataTrain)</span></code></pre></div>
<pre><code>##      shares         data_channel_is_socmed
##  Min.   :     1.0   Min.   :0.00000       
##  1st Qu.:   922.2   1st Qu.:0.00000       
##  Median :  1400.0   Median :0.00000       
##  Mean   :  3582.0   Mean   :0.05105       
##  3rd Qu.:  2700.0   3rd Qu.:0.00000       
##  Max.   :690400.0   Max.   :1.00000       
##    kw_max_avg     self_reference_avg_sharess
##  Min.   :     0   Min.   :     0            
##  1st Qu.:  3532   1st Qu.:  1031            
##  Median :  4273   Median :  2200            
##  Mean   :  5559   Mean   :  6269            
##  3rd Qu.:  5954   3rd Qu.:  5153            
##  Max.   :298400   Max.   :690400            
##    kw_min_avg       kw_avg_avg   
##  Min.   :   0.0   Min.   :    0  
##  1st Qu.:   0.0   1st Qu.: 2366  
##  Median : 989.2   Median : 2855  
##  Mean   :1082.4   Mean   : 3076  
##  3rd Qu.:1996.0   3rd Qu.: 3554  
##  Max.   :3594.6   Max.   :33536  
##  self_reference_max_shares global_subjectivity
##  Min.   :     0            Min.   :0.0000     
##  1st Qu.:  1100            1st Qu.:0.3965     
##  Median :  2850            Median :0.4522     
##  Mean   : 10015            Mean   :0.4422     
##  3rd Qu.:  8000            3rd Qu.:0.5054     
##  Max.   :843300            Max.   :1.0000
</code></pre>
<p>As will be used later, the median number of shares for an article is 1400. From the summaries, you can tell which variables are indicator variables (those with a min of 0 and max of 1; i.e. <code>data_channel_is_socmed</code> and <code>global_subjectivity</code>.) This also shows that the data will need to be standardized when I use the ensemble method.</p>
<p>Overall, the data is quite varied (especially the average variables). You can see that the <code>shares</code> data and <code>self_reference_avg_share</code> data have the same range.</p>
<h2 id="compare-fit-stats-function-to-compare-models">Compare Fit Stats Function to compare models</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>compareFitStats &lt;-<span class="st"> </span><span class="cf">function</span>(fit1, fit2){</span>
<span id="cb13-2"><a href="#cb13-2"></a>  <span class="kw">require</span>(MuMIn)</span>
<span id="cb13-3"><a href="#cb13-3"></a>  fitStats &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fitStat =</span> <span class="kw">c</span>(<span class="st">&quot;Adj R Square&quot;</span>, <span class="st">&quot;AIC&quot;</span>, <span class="st">&quot;AICc&quot;</span>, <span class="st">&quot;BIC&quot;</span>), </span>
<span id="cb13-4"><a href="#cb13-4"></a>              <span class="dt">col1 =</span> <span class="kw">round</span>(<span class="kw">c</span>(<span class="kw">summary</span>(fit1)<span class="op">$</span>adj.r.squared, <span class="kw">AIC</span>(fit1), </span>
<span id="cb13-5"><a href="#cb13-5"></a>                             MuMIn<span class="op">::</span><span class="kw">AICc</span>(fit1), <span class="kw">BIC</span>(fit1)), <span class="dv">3</span>), </span>
<span id="cb13-6"><a href="#cb13-6"></a>              <span class="dt">col2 =</span> <span class="kw">round</span>(<span class="kw">c</span>(<span class="kw">summary</span>(fit2)<span class="op">$</span>adj.r.squared, <span class="kw">AIC</span>(fit2), </span>
<span id="cb13-7"><a href="#cb13-7"></a>                             MuMIn<span class="op">::</span><span class="kw">AICc</span>(fit2), <span class="kw">BIC</span>(fit2)), <span class="dv">3</span>))</span>
<span id="cb13-8"><a href="#cb13-8"></a>  </span>
<span id="cb13-9"><a href="#cb13-9"></a>  <span class="co">#put names on returned df  </span></span>
<span id="cb13-10"><a href="#cb13-10"></a>  calls &lt;-<span class="st"> </span><span class="kw">as.list</span>(<span class="kw">match.call</span>())</span>
<span id="cb13-11"><a href="#cb13-11"></a>  calls[[<span class="dv">1</span>]] &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb13-12"><a href="#cb13-12"></a>  <span class="kw">names</span>(fitStats[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>])&lt;-<span class="st"> </span><span class="kw">unlist</span>(calls)</span>
<span id="cb13-13"><a href="#cb13-13"></a>  fitStats</span>
<span id="cb13-14"><a href="#cb13-14"></a>}</span></code></pre></div>
<h1 id="linear-regression-model">Linear Regression Model</h1>
<p>I will begin by running a regression model with all of the variables.</p>
<p><strong>allVarFit</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>allVarFit &lt;-<span class="st"> </span><span class="kw">lm</span>(shares <span class="op">~</span>., <span class="dt">data =</span> dataTrain)</span>
<span id="cb14-2"><a href="#cb14-2"></a></span>
<span id="cb14-3"><a href="#cb14-3"></a>allVarFit</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = shares ~ ., data = dataTrain)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -3.513e+03                   1.821e+02  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -2.727e-01                   4.343e-04  
##                 kw_min_avg                  kw_avg_avg  
##                 -6.544e-01                   2.560e+00  
##  self_reference_max_shares         global_subjectivity  
##                  1.062e-03                   3.215e+03
</code></pre>
<p>Then, I will create another linear model with the interaction effects to see if it makes a difference.</p>
<p><strong>intLM</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>intLM &lt;-<span class="st"> </span><span class="kw">lm</span>(shares <span class="op">~</span><span class="st"> </span>data_channel_is_socmed <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span>kw_min_avg <span class="op">+</span></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb16-5"><a href="#cb16-5"></a><span class="st">                  </span>self_reference_max_shares <span class="op">+</span></span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="st">                  </span>global_subjectivity <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-7"><a href="#cb16-7"></a><span class="st">                  </span>kw_avg_avg<span class="op">:</span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-8"><a href="#cb16-8"></a><span class="st">                  </span>self_reference_max_shares<span class="op">:</span>self_reference_avg_sharess, </span>
<span id="cb16-9"><a href="#cb16-9"></a>                <span class="dt">data =</span> dataTrain</span>
<span id="cb16-10"><a href="#cb16-10"></a>)</span>
<span id="cb16-11"><a href="#cb16-11"></a></span>
<span id="cb16-12"><a href="#cb16-12"></a>intLM</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = shares ~ data_channel_is_socmed + kw_max_avg + kw_min_avg + 
##     self_reference_avg_sharess + kw_avg_avg + self_reference_max_shares + 
##     global_subjectivity + kw_avg_avg:kw_max_avg + self_reference_max_shares:self_reference_avg_sharess, 
##     data = dataTrain)
## 
## Coefficients:
##                                          (Intercept)  
##                                           -3.351e+03  
##                               data_channel_is_socmed  
##                                            1.302e+02  
##                                           kw_max_avg  
##                                           -2.150e-01  
##                                           kw_min_avg  
##                                           -6.083e-01  
##                           self_reference_avg_sharess  
##                                            2.813e-02  
##                                           kw_avg_avg  
##                                            2.386e+00  
##                            self_reference_max_shares  
##                                            4.767e-03  
##                                  global_subjectivity  
##                                            2.946e+03  
##                                kw_max_avg:kw_avg_avg  
##                                           -1.504e-06  
## self_reference_avg_sharess:self_reference_max_shares  
##                                           -6.395e-08
</code></pre>
<h2 id="comparison-of-two-models">Comparison of Two Models</h2>
<p>I will compare the two models using the compareFitStats function.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">compareFitStats</span>(allVarFit, intLM)</span></code></pre></div>
<pre><code>##        fitStat       col1       col2
## 1 Adj R Square      0.018      0.018
## 2          AIC 101888.286 101888.773
## 3         AICc 101888.325 101888.829
## 4          BIC 101946.311 101959.692
</code></pre>
<h3 id="analysis-1">Analysis</h3>
<p>Neither model fits the data well. I am going to try a logistic regression model instead.</p>
<h1 id="logistic-model">Logistic Model</h1>
<p>First, I need to create a logical variable to reference whether the number of shares is less than 1400 or greater than 1400. I am still going to use the same variables as those in my linear regression attempt.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a>data1 &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">logShares =</span> <span class="kw">ifelse</span>(shares <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="dv">1</span>, <span class="dv">0</span>)) </span>
<span id="cb20-2"><a href="#cb20-2"></a>data1 &lt;-<span class="st"> </span>data1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(logShares, <span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>shares)</span>
<span id="cb20-3"><a href="#cb20-3"></a></span>
<span id="cb20-4"><a href="#cb20-4"></a><span class="co">#Create New Test and Train Set with logShares Variable. Set seed gives same train and test set. </span></span>
<span id="cb20-5"><a href="#cb20-5"></a></span>
<span id="cb20-6"><a href="#cb20-6"></a><span class="co"># set seed</span></span>
<span id="cb20-7"><a href="#cb20-7"></a><span class="kw">set.seed</span>(<span class="dv">130</span>)</span>
<span id="cb20-8"><a href="#cb20-8"></a><span class="co"># Set indices</span></span>
<span id="cb20-9"><a href="#cb20-9"></a>train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data1), <span class="dt">size =</span><span class="kw">nrow</span>(data1)<span class="op">*</span><span class="fl">0.7</span>)</span>
<span id="cb20-10"><a href="#cb20-10"></a>test &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data1), train)</span>
<span id="cb20-11"><a href="#cb20-11"></a></span>
<span id="cb20-12"><a href="#cb20-12"></a><span class="co"># Make Train and Test Sets  </span></span>
<span id="cb20-13"><a href="#cb20-13"></a></span>
<span id="cb20-14"><a href="#cb20-14"></a>data1Train &lt;-<span class="st"> </span>data1[train, ]</span>
<span id="cb20-15"><a href="#cb20-15"></a>data1Test &lt;-<span class="st"> </span>data1[test, ]</span>
<span id="cb20-16"><a href="#cb20-16"></a></span>
<span id="cb20-17"><a href="#cb20-17"></a>data1</span></code></pre></div>
<pre><code>## # A tibble: 6,661 x 8
##    logShares data_channel_is~ kw_max_avg self_reference_~
##        &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;
##  1         0                0          0             496 
##  2         0                0          0               0 
##  3         1                0          0             918 
##  4         0                0          0               0 
##  5         0                0          0            3151.
##  6         0                0          0            8500 
##  7         0                0          0            3151.
##  8         0                0          0            3151.
##  9         1                0          0               0 
## 10         0                0          0               0 
## # ... with 6,651 more rows, and 4 more variables:
## #   kw_min_avg &lt;dbl&gt;, kw_avg_avg &lt;dbl&gt;,
## #   self_reference_max_shares &lt;dbl&gt;,
## #   global_subjectivity &lt;dbl&gt;
</code></pre>
<p>Here, I will fit a logistic regression model using the <code>glm()</code> function with the <code>&quot;binomial&quot;</code> family. I will look at how the removal of certain variables changes the AIC value for each model.</p>
<p><strong>GLM ALL Model</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a>glmALL &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span>., <span class="dt">data =</span> data1Train, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb22-2"><a href="#cb22-2"></a></span>
<span id="cb22-3"><a href="#cb22-3"></a>glmALL</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ ., family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -1.628e+00                   1.105e+00  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -6.630e-05                   7.798e-06  
##                 kw_min_avg                  kw_avg_avg  
##                 -1.057e-04                   5.595e-04  
##  self_reference_max_shares         global_subjectivity  
##                  6.940e-08                   7.835e-01  
## 
## Degrees of Freedom: 4661 Total (i.e. Null);  4654 Residual
## Null Deviance:       6460 
## Residual Deviance: 6186  AIC: 6202
</code></pre>
<p>I will remove <code>kw_avg_min</code> variable just to be able to compare fits of the two logistic models.</p>
<p><strong>GLM All but One Model</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a>glmAllButOne &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span>data_channel_is_socmed <span class="op">+</span><span class="st"> </span></span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb24-3"><a href="#cb24-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb24-4"><a href="#cb24-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb24-5"><a href="#cb24-5"></a><span class="st">                  </span>self_reference_max_shares <span class="op">+</span></span>
<span id="cb24-6"><a href="#cb24-6"></a><span class="st">                  </span>global_subjectivity, </span>
<span id="cb24-7"><a href="#cb24-7"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb24-8"><a href="#cb24-8"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb24-9"><a href="#cb24-9"></a>)</span>
<span id="cb24-10"><a href="#cb24-10"></a></span>
<span id="cb24-11"><a href="#cb24-11"></a>glmAllButOne</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ data_channel_is_socmed + kw_max_avg + 
##     self_reference_avg_sharess + kw_avg_avg + self_reference_max_shares + 
##     global_subjectivity, family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -1.514e+00                   1.104e+00  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -5.326e-05                   8.270e-06  
##                 kw_avg_avg   self_reference_max_shares  
##                  4.637e-04                  -1.379e-07  
##        global_subjectivity  
##                  7.670e-01  
## 
## Degrees of Freedom: 4661 Total (i.e. Null);  4655 Residual
## Null Deviance:       6460 
## Residual Deviance: 6196  AIC: 6210
</code></pre>
<h3 id="analysis-2">Analysis</h3>
<p>The AIC for the glmAllButOne model is much higher than the all variable model. I will remove another variable, <code>global_subjectivity</code> (next smallest correlation) and see if that helps.</p>
<p><strong>glm All But Two Model</strong></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a>glmAllButTwo &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span>data_channel_is_socmed <span class="op">+</span><span class="st"> </span></span>
<span id="cb26-2"><a href="#cb26-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb26-3"><a href="#cb26-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb26-5"><a href="#cb26-5"></a><span class="st">                  </span>self_reference_max_shares, </span>
<span id="cb26-6"><a href="#cb26-6"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb26-7"><a href="#cb26-7"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb26-8"><a href="#cb26-8"></a>)</span>
<span id="cb26-9"><a href="#cb26-9"></a></span>
<span id="cb26-10"><a href="#cb26-10"></a>glmAllButTwo</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ data_channel_is_socmed + kw_max_avg + 
##     self_reference_avg_sharess + kw_avg_avg + self_reference_max_shares, 
##     family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)      data_channel_is_socmed  
##                 -1.186e+00                   1.113e+00  
##                 kw_max_avg  self_reference_avg_sharess  
##                 -5.373e-05                   9.100e-06  
##                 kw_avg_avg   self_reference_max_shares  
##                  4.668e-04                  -2.737e-07  
## 
## Degrees of Freedom: 4661 Total (i.e. Null);  4656 Residual
## Null Deviance:       6460 
## Residual Deviance: 6204  AIC: 6216
</code></pre>
<p>##Analysis<br />
Remove <code>data_channel_is_socmed</code>.</p>
<p><strong>glm All But Three Model</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a>glmAllButThree &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span></span>
<span id="cb28-2"><a href="#cb28-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb28-4"><a href="#cb28-4"></a><span class="st">                  </span>kw_avg_avg <span class="op">+</span></span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="st">                  </span>self_reference_max_shares,</span>
<span id="cb28-6"><a href="#cb28-6"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb28-7"><a href="#cb28-7"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb28-8"><a href="#cb28-8"></a>)</span>
<span id="cb28-9"><a href="#cb28-9"></a></span>
<span id="cb28-10"><a href="#cb28-10"></a>glmAllButThree</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ kw_max_avg + self_reference_avg_sharess + 
##     kw_avg_avg + self_reference_max_shares, family = &quot;binomial&quot;, 
##     data = data1Train)
## 
## Coefficients:
##                (Intercept)                  kw_max_avg  
##                 -1.140e+00                  -5.515e-05  
## self_reference_avg_sharess                  kw_avg_avg  
##                  9.951e-06                   4.699e-04  
##  self_reference_max_shares  
##                 -3.260e-07  
## 
## Degrees of Freedom: 4661 Total (i.e. Null);  4657 Residual
## Null Deviance:       6460 
## Residual Deviance: 6262  AIC: 6272
</code></pre>
<p>##Analysis<br />
Remove <code>self_reference_max_shares</code>.</p>
<p><strong>glm All But Four Model</strong></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a>glmAllButFour &lt;-<span class="st"> </span><span class="kw">glm</span>(logShares <span class="op">~</span><span class="st"> </span></span>
<span id="cb30-2"><a href="#cb30-2"></a><span class="st">                  </span>kw_max_avg <span class="op">+</span><span class="st"> </span></span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="st">                  </span>self_reference_avg_sharess <span class="op">+</span></span>
<span id="cb30-4"><a href="#cb30-4"></a><span class="st">                  </span>kw_avg_avg, </span>
<span id="cb30-5"><a href="#cb30-5"></a>                <span class="dt">data =</span> data1Train, </span>
<span id="cb30-6"><a href="#cb30-6"></a>                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb30-7"><a href="#cb30-7"></a>)</span>
<span id="cb30-8"><a href="#cb30-8"></a>glmAllButFour</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = logShares ~ kw_max_avg + self_reference_avg_sharess + 
##     kw_avg_avg, family = &quot;binomial&quot;, data = data1Train)
## 
## Coefficients:
##                (Intercept)                  kw_max_avg  
##                 -1.141e+00                  -5.527e-05  
## self_reference_avg_sharess                  kw_avg_avg  
##                  9.393e-06                   4.703e-04  
## 
## Degrees of Freedom: 4661 Total (i.e. Null);  4658 Residual
## Null Deviance:       6460 
## Residual Deviance: 6262  AIC: 6270
</code></pre>
<h2 id="analysis-3">Analysis</h2>
<p>Did not help. Will keep <code>self_reference_max_shares</code>.</p>
<h2 id="comparison-of-all-four-logistic-models">Comparison of all Four Logistic Models</h2>
<p>I will predict the test data and compare the RMSEs of those.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a><span class="co">#Make predictions  </span></span>
<span id="cb32-2"><a href="#cb32-2"></a>predALL &lt;-<span class="st"> </span><span class="kw">predict</span>(glmALL, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-3"><a href="#cb32-3"></a>predALLbutOne &lt;-<span class="st"> </span><span class="kw">predict</span>(glmAllButOne, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-4"><a href="#cb32-4"></a>predALLbutTwo &lt;-<span class="st"> </span><span class="kw">predict</span>(glmAllButTwo, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-5"><a href="#cb32-5"></a>predALLbutThree &lt;-<span class="st"> </span><span class="kw">predict</span>(glmAllButThree, <span class="dt">newdata =</span> data1Test, <span class="dt">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb32-6"><a href="#cb32-6"></a></span>
<span id="cb32-7"><a href="#cb32-7"></a><span class="co">#Calculate RMSE  </span></span>
<span id="cb32-8"><a href="#cb32-8"></a>AllMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALL)</span>
<span id="cb32-9"><a href="#cb32-9"></a>OneMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALLbutOne)</span>
<span id="cb32-10"><a href="#cb32-10"></a>TwoMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALLbutTwo)</span>
<span id="cb32-11"><a href="#cb32-11"></a>ThreeMSE &lt;-<span class="st"> </span><span class="kw">rmse</span>(data1Test<span class="op">$</span>logShares, predALLbutThree)</span>
<span id="cb32-12"><a href="#cb32-12"></a></span>
<span id="cb32-13"><a href="#cb32-13"></a>matMSE &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(AllMSE, OneMSE, TwoMSE, ThreeMSE), <span class="dt">nrow =</span> <span class="dv">1</span>, <span class="dt">ncol =</span> <span class="dv">4</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</span>
<span id="cb32-14"><a href="#cb32-14"></a></span>
<span id="cb32-15"><a href="#cb32-15"></a>matMSE</span></code></pre></div>
<pre><code>##           [,1]     [,2]    [,3]      [,4]
## [1,] 0.7923079 0.787188 0.78528 0.7626693
</code></pre>
<h3 id="analysis-4">Analysis</h3>
<p>The glmAllButThree produces the smallest MSE. I will use this as my model for the data. The glmAllButThree also produces the highest AIC value.</p>
<h1 id="ensemble-model">Ensemble Model</h1>
<p>From the past homework assigment, it seems that each of the ensemble methods that we covered are equally efficient. I am going to use the Random Forest model to fit my data. Overall, Random Forest is better than bagging and boosting trees take longer to do. I will add a class variable (less than 1400, more than 1400) that I will predict on the test data.</p>
<h2 id="fix-train-and-test-data">Fix Train and Test Data</h2>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a>dataTrain &lt;-<span class="st"> </span>dataTrain <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">group =</span> <span class="kw">ifelse</span>(shares <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="st">&quot;less than 1400&quot;</span>, <span class="st">&quot;more than 1400&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb34-2"><a href="#cb34-2"></a><span class="st">  </span><span class="kw">select</span>(group, kw_max_avg, self_reference_avg_sharess, </span>
<span id="cb34-3"><a href="#cb34-3"></a>         kw_min_avg, kw_avg_avg, self_reference_max_shares, </span>
<span id="cb34-4"><a href="#cb34-4"></a>         global_subjectivity) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">collect</span>()</span>
<span id="cb34-5"><a href="#cb34-5"></a></span>
<span id="cb34-6"><a href="#cb34-6"></a>dataTrain<span class="op">$</span>group &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dataTrain<span class="op">$</span>group)</span>
<span id="cb34-7"><a href="#cb34-7"></a></span>
<span id="cb34-8"><a href="#cb34-8"></a>dataTrain</span></code></pre></div>
<pre><code>## # A tibble: 4,662 x 7
##    group kw_max_avg self_reference_~ kw_min_avg
##    &lt;fct&gt;      &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;
##  1 more~     10975             9340       1818.
##  2 less~      3535.            1656.      1809.
##  3 less~      5605.            3020       1100 
##  4 more~      7700             1400       2969.
##  5 less~      3272.            1000       1051.
##  6 less~      3927.            2600          0 
##  7 less~      7632              914       1783.
##  8 less~      3281.            5450       2623.
##  9 more~      7182.            7950       3510.
## 10 less~      4275.            1024.         0 
## # ... with 4,652 more rows, and 3 more variables:
## #   kw_avg_avg &lt;dbl&gt;, self_reference_max_shares &lt;dbl&gt;,
## #   global_subjectivity &lt;dbl&gt;
</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a>dataTest &lt;-<span class="st"> </span>dataTest <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">group =</span><span class="kw">ifelse</span>(shares <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1400</span>, <span class="st">&quot;less than 1400&quot;</span>, <span class="st">&quot;more than 1400&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="st">  </span><span class="kw">select</span>(group, kw_max_avg, self_reference_avg_sharess, </span>
<span id="cb36-3"><a href="#cb36-3"></a>         kw_min_avg, kw_avg_avg, self_reference_max_shares, </span>
<span id="cb36-4"><a href="#cb36-4"></a>         global_subjectivity) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">collect</span>()</span>
<span id="cb36-5"><a href="#cb36-5"></a></span>
<span id="cb36-6"><a href="#cb36-6"></a>dataTest<span class="op">$</span>group &lt;-<span class="st"> </span><span class="kw">as.factor</span>(dataTest<span class="op">$</span>group)</span></code></pre></div>
<p><strong>Random Forest Model</strong></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># train control parameters  </span></span>
<span id="cb37-2"><a href="#cb37-2"></a>trctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>, <span class="dt">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb37-3"><a href="#cb37-3"></a></span>
<span id="cb37-4"><a href="#cb37-4"></a>rfFit&lt;-<span class="st"> </span><span class="kw">train</span>(group<span class="op">~</span>., <span class="dt">data =</span> dataTrain, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> trctrl, <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span></code></pre></div>
<p><strong>Predict Data with rfFit</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a>rfPred &lt;-<span class="st"> </span><span class="kw">predict</span>(rfFit, <span class="kw">select</span>(dataTest, <span class="op">-</span><span class="st">&quot;group&quot;</span>))</span></code></pre></div>
<p><strong>Compare Predictions to Actual</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>fullTbl &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">data.frame</span>(rfPred, dataTest<span class="op">$</span>group))</span>
<span id="cb39-2"><a href="#cb39-2"></a></span>
<span id="cb39-3"><a href="#cb39-3"></a>fullTbl</span></code></pre></div>
<pre><code>##                 dataTest.group
## rfPred           less than 1400 more than 1400
##   less than 1400            683            424
##   more than 1400            384            508
</code></pre>
<p><strong>Find MisClassification Rate</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a>rfMis &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(fullTbl)<span class="op">/</span><span class="kw">sum</span>(fullTbl))</span>
<span id="cb41-2"><a href="#cb41-2"></a></span>
<span id="cb41-3"><a href="#cb41-3"></a>rfMis</span></code></pre></div>
<pre><code>## [1] 0.4042021
</code></pre>
<h3 id="analysis-5">Analysis</h3>
<p>This a pretty large misclassification rate. I will choose less variables to see if it helps.</p>
<p><strong>One Variable Random Forest</strong></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="co"># no kw_min_avg, has lowest correlation </span></span>
<span id="cb43-2"><a href="#cb43-2"></a>rf1 &lt;-<span class="st"> </span><span class="kw">train</span>(group <span class="op">~</span><span class="st"> </span>kw_max_avg <span class="op">+</span><span class="st"> </span>self_reference_avg_sharess <span class="op">+</span><span class="st">  </span></span>
<span id="cb43-3"><a href="#cb43-3"></a><span class="st">         </span><span class="op">+</span><span class="st"> </span>kw_avg_avg <span class="op">+</span><span class="st"> </span>self_reference_max_shares <span class="op">+</span><span class="st">  </span></span>
<span id="cb43-4"><a href="#cb43-4"></a><span class="st">         </span>global_subjectivity, <span class="dt">data =</span> dataTrain, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> trctrl, <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))  </span></code></pre></div>
<p><strong>Predict Data with rf1</strong></p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1"></a>rf1Pred &lt;-<span class="st"> </span><span class="kw">predict</span>(rf1, <span class="kw">select</span>(dataTest, <span class="op">-</span><span class="st">&quot;group&quot;</span>))  </span></code></pre></div>
<p><strong>Compare Predictions to Actual</strong></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a>fullTbl &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">data.frame</span>(rf1Pred, dataTest<span class="op">$</span>group))  </span>
<span id="cb45-2"><a href="#cb45-2"></a></span>
<span id="cb45-3"><a href="#cb45-3"></a>fullTbl</span></code></pre></div>
<pre><code>##                 dataTest.group
## rf1Pred          less than 1400 more than 1400
##   less than 1400            681            428
##   more than 1400            386            504
</code></pre>
<p><strong>Find MisClassification Rate</strong></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>rfMis &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(fullTbl)<span class="op">/</span><span class="kw">sum</span>(fullTbl))</span>
<span id="cb47-2"><a href="#cb47-2"></a></span>
<span id="cb47-3"><a href="#cb47-3"></a>rfMis</span></code></pre></div>
<pre><code>## [1] 0.4072036
</code></pre>
<h3 id="analysis-6">Analysis</h3>
<p>This does not help. I will keep my first Random Forest Model for prediction.</p>
<h1 id="models-used">Models Used</h1>
<p>Overall, I have chosen the following models for my data.</p>
<ol>
<li>glmAllbutThree: Logistic Regression Model</li>
<li>rfFit : Random Forest Model</li>
</ol>

</body>
</html>
